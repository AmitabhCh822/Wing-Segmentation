{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVeinDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, mask_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "            image_dir (str): Path to image folder\n",
    "            mask_dir (str): Path to mask folder\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image ID\n",
    "        image_id = self.data.iloc[idx]['ImageID']\n",
    "        \n",
    "        # Load image and mask\n",
    "        img_path = os.path.join(self.image_dir, f\"{image_id}.png\")\n",
    "        mask_path = os.path.join(self.mask_dir, f\"{image_id}.jpg\")\n",
    "        \n",
    "        # Open and convert to grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        image = torch.from_numpy(np.array(image)).float() / 255.0\n",
    "        mask = torch.from_numpy(np.array(mask)).float() / 255.0\n",
    "\n",
    "        # Add channel dimension\n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_display_all_bat_images(csv_file, image_dir, mask_dir):\n",
    "    \"\"\"\n",
    "    Group and display all images from all bats\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "        image_dir (str): Path to image folder\n",
    "        mask_dir (str): Path to mask folder\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Group by BatID\n",
    "    grouped = df.groupby('BatID')\n",
    "    \n",
    "    # Create dataset for loading images\n",
    "    dataset = SimpleVeinDataset(csv_file, image_dir, mask_dir)\n",
    "    \n",
    "    # Get all bat IDs\n",
    "    all_bats = list(grouped.groups.keys())\n",
    "    \n",
    "    for bat_id in all_bats:\n",
    "        # Get all image IDs for this bat\n",
    "        bat_images = grouped.get_group(bat_id)\n",
    "        num_images = len(bat_images)\n",
    "        \n",
    "        # Create a figure with enough subplots for all images and masks\n",
    "        fig, axes = plt.subplots(num_images, 2, figsize=(10, 5*num_images))\n",
    "        plt.suptitle(f'Bat ID: {bat_id}', fontsize=16)\n",
    "        \n",
    "        # If there's only one image, wrap axes in list\n",
    "        if num_images == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        # Load and display each image for this bat\n",
    "        for idx, (_, row) in enumerate(bat_images.iterrows()):\n",
    "            # Find index in dataset\n",
    "            dataset_idx = df[df['ImageID'] == row['ImageID']].index[0]\n",
    "            image, mask = dataset[dataset_idx]\n",
    "            \n",
    "            # Display image\n",
    "            axes[idx, 0].imshow(image.squeeze(), cmap='gray')\n",
    "            axes[idx, 0].set_title(f'Image {row[\"ImageID\"]}')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            # Display mask\n",
    "            axes[idx, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "            axes[idx, 1].set_title(f'Mask {row[\"ImageID\"]}')\n",
    "            axes[idx, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "group_and_display_all_bat_images(\n",
    "    csv_file='your_data.csv',\n",
    "    image_dir='path/to/Images',\n",
    "    mask_dir='path/to/Masks'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "def analyze_bat_distribution(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of images across bats\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatId and ImageID columns\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    grouped = df.groupby('BatID')\n",
    "    \n",
    "    # Get distribution statistics\n",
    "    image_counts = grouped.size()\n",
    "    \n",
    "    print(\"\\nBat Image Distribution:\")\n",
    "    print(f\"Total number of bats: {len(image_counts)}\")\n",
    "    print(f\"Total number of images: {len(df)}\")\n",
    "    print(f\"Average images per bat: {image_counts.mean():.2f}\")\n",
    "    print(f\"Min images per bat: {image_counts.min()}\")\n",
    "    print(f\"Max images per bat: {image_counts.max()}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(image_counts, bins='auto')\n",
    "    plt.title('Distribution of Images per Bat')\n",
    "    plt.xlabel('Number of Images')\n",
    "    plt.ylabel('Number of Bats')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display counts for each bat\n",
    "    print(\"\\nDetailed image counts per bat:\")\n",
    "    for bat_id, count in image_counts.items():\n",
    "        print(f\"Bat {bat_id}: {count} images\")\n",
    "\n",
    "\"\"\"\n",
    "**Uncomment this to view all the wing images for each bat!**\n",
    "group_and_display_all_bat_images(\n",
    "    csv_file='../Dataset/dataset.csv',\n",
    "    image_dir='../Dataset/Images',\n",
    "    mask_dir='../Dataset/Masks'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def create_train_val_test_splits(csv_file, image_dir, mask_dir, test_size=0.15, val_size=0.15, batch_size=1, random_state=420):\n",
    "    \"\"\"\n",
    "    Create train, validation and test splits while keeping all images from the same bat together\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "        image_dir (str): Path to image folder\n",
    "        mask_dir (str): Path to mask folder\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "        val_size (float): Proportion of training data to use for validation\n",
    "        batch_size (int): Batch size for dataloaders\n",
    "        random_state (int): Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Get unique bat IDs\n",
    "    unique_bats = df['BatID'].unique()\n",
    "    \n",
    "    # First split off the test set\n",
    "    train_val_bats, test_bats = train_test_split(\n",
    "        unique_bats, \n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Then split the remaining data into train and validation\n",
    "    train_bats, val_bats = train_test_split(\n",
    "        train_val_bats,\n",
    "        test_size=val_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Create full dataset\n",
    "    full_dataset = SimpleVeinDataset(csv_file, image_dir, mask_dir)\n",
    "    \n",
    "    # Get indices for each split\n",
    "    train_indices = df[df['BatID'].isin(train_bats)].index.tolist()\n",
    "    val_indices = df[df['BatID'].isin(val_bats)].index.tolist()\n",
    "    test_indices = df[df['BatID'].isin(test_bats)].index.tolist()\n",
    "    \n",
    "    # Create subset datasets\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Print split information\n",
    "    print(\"\\nDataset Split Information:\")\n",
    "    print(f\"Total number of bats: {len(unique_bats)}\")\n",
    "    print(f\"Number of training bats: {len(train_bats)}\")\n",
    "    print(f\"Number of validation bats: {len(val_bats)}\")\n",
    "    print(f\"Number of test bats: {len(test_bats)}\")\n",
    "    print(f\"\\nTotal number of images: {len(df)}\")\n",
    "    print(f\"Number of training images: {len(train_indices)}\")\n",
    "    print(f\"Number of validation images: {len(val_indices)}\")\n",
    "    print(f\"Number of test images: {len(test_indices)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def verify_data_splits(train_loader, val_loader, test_loader, num_samples=2):\n",
    "    \"\"\"\n",
    "    Verify the splits by displaying some samples from each split\n",
    "    \"\"\"\n",
    "    def show_batch(loader, title):\n",
    "        # Get a batch\n",
    "        images, masks = next(iter(loader))\n",
    "        \n",
    "        # Display up to num_samples from the batch\n",
    "        n = min(num_samples, len(images))\n",
    "        fig, axes = plt.subplots(n, 2, figsize=(10, 5*n))\n",
    "        if n == 1:  # Handle case where there's only one sample\n",
    "            axes = axes.reshape(1, -1)\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "        \n",
    "        for i in range(n):\n",
    "            # Display image\n",
    "            axes[i, 0].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i, 0].set_title(f'Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Display mask\n",
    "            axes[i, 1].imshow(masks[i].squeeze(), cmap='gray')\n",
    "            axes[i, 1].set_title(f'Mask {i+1}')\n",
    "            axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Show samples from all splits\n",
    "    print(\"\\nDisplaying training samples:\")\n",
    "    show_batch(train_loader, \"Training Samples\")\n",
    "    \n",
    "    print(\"\\nDisplaying validation samples:\")\n",
    "    show_batch(val_loader, \"Validation Samples\")\n",
    "    \n",
    "    print(\"\\nDisplaying test samples:\")\n",
    "    show_batch(test_loader, \"Test Samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the splits\n",
    "train_loader, val_loader, test_loader  = create_train_val_test_splits(\n",
    "    csv_file='../Dataset/dataset.csv',\n",
    "    image_dir='../Dataset/Images',\n",
    "    mask_dir='../Dataset//Masks',\n",
    "    test_size=0.2,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Verify the splits\n",
    "verify_data_splits(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Convolution block:\n",
    "    (Conv2d -> BatchNorm -> ReLU) * 2\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[32, 64, 128, 256, 512, 1024]):\n",
    "        \"\"\"\n",
    "        Standard U-Net architecture\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (1 for grayscale, 3 for RGB)\n",
    "            out_channels (int): Number of output channels (1 for binary segmentation)\n",
    "            features (list): Feature dimensions for each level\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Downsampling/Encoder path\n",
    "        in_feat = in_channels\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_feat, feature))\n",
    "            in_feat = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Upsampling/Decoder path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature * 2, feature, kernel_size=2, stride=2\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Optional sigmoid for binary segmentation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store skip connections\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder path\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Reverse skip connections list for easier access\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Decoder path\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)  # Upsample\n",
    "            skip = skip_connections[idx//2]\n",
    "\n",
    "            # Handle cases where input dimensions aren't perfectly divisible by 2\n",
    "            #if x.shape != skip.shape:\n",
    "                #x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            # Concatenate with skip connection\n",
    "            concat_skip = torch.cat((skip, x), dim=1)\n",
    "            \n",
    "            # Double convolution\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        # Final 1x1 convolution and sigmoid\n",
    "        return self.sigmoid(self.final_conv(x))\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(\n",
    "    in_channels=1,  # 1 for grayscale\n",
    "    out_channels=1, # 1 for binary segmentation\n",
    "    features=[32, 64, 128, 256, 512, 1024]  # Feature dimensions at each level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimizer and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten predictions and targets\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate Dice coefficient\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, bce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        dice_loss = self.dice(predictions, targets)\n",
    "        bce_loss = self.bce(predictions, targets)\n",
    "        \n",
    "        return self.dice_weight * dice_loss + self.bce_weight * bce_loss\n",
    "\n",
    "def setup_training(model, learning_rate=1e-4, loss_type='combined'):\n",
    "    \"\"\"\n",
    "    Set up loss function and optimizer for training\n",
    "    \n",
    "    Args:\n",
    "        model: The U-Net model\n",
    "        learning_rate: Learning rate for the optimizer\n",
    "        loss_type: One of 'bce', 'dice', or 'combined'\n",
    "        \n",
    "    Returns:\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "    \"\"\"\n",
    "    # Set up loss function\n",
    "    if loss_type == 'bce':\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss_type == 'dice':\n",
    "        criterion = DiceLoss()\n",
    "    elif loss_type == 'combined':\n",
    "        criterion = CombinedLoss(dice_weight=0.2, bce_weight=0.8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Set up learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    return criterion, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training\n",
    "criterion, optimizer, scheduler = setup_training(\n",
    "    model,\n",
    "    learning_rate=0.0001,\n",
    "    loss_type='dice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                scheduler, \n",
    "                num_epochs, \n",
    "                device,\n",
    "                save_path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Training loop for U-Net model with improved progress tracking\n",
    "    \"\"\"\n",
    "    # Initialize best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(f\"Starting training at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Training on device: {device}\")\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    # Main epoch loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_dice = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        print(\"Training...\")\n",
    "        for images, masks in train_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if batch_count % 1 == 0:  # Print every batch\n",
    "                print(f\"Batch {batch_count}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average training metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        print(\"\\nValidating...\")\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(predictions, masks)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Print progress\n",
    "                if batch_count % 1 == 0:  # Print every batch\n",
    "                    print(f\"Batch {batch_count}/{len(val_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average validation metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "            }, save_path)\n",
    "            print(f'Saved new best model with validation loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "    # Final plot\n",
    "    plot_training_history(train_losses, val_losses)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_training_history(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss history\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=40,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set and compute medical imaging metrics\n",
    "    \n",
    "    Args:\n",
    "        model: The trained U-Net model\n",
    "        test_loader: DataLoader for the test set\n",
    "        criterion: Loss function\n",
    "        device: Device to run evaluation on\n",
    "        threshold: Threshold for binary prediction (default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing various evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Initialize metrics\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    # For ROC and AUC calculation\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # For confusion matrix based metrics\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    total_tn = 0\n",
    "    \n",
    "    print(\"Evaluating model on test set...\")\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Move to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, masks)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Convert to binary predictions using threshold\n",
    "            binary_preds = (predictions > threshold).float()\n",
    "            \n",
    "            # Accumulate predictions and targets for ROC/AUC calculation\n",
    "            all_preds.extend(predictions.view(-1).cpu().numpy())\n",
    "            all_targets.extend(masks.view(-1).cpu().numpy())\n",
    "            \n",
    "            # Update confusion matrix for metrics calculation\n",
    "            for i in range(len(images)):\n",
    "                pred = binary_preds[i].view(-1)\n",
    "                mask = masks[i].view(-1)\n",
    "                \n",
    "                # Calculate confusion matrix elements\n",
    "                tp = torch.sum((pred == 1) & (mask == 1)).item()\n",
    "                fp = torch.sum((pred == 1) & (mask == 0)).item()\n",
    "                fn = torch.sum((pred == 0) & (mask == 1)).item()\n",
    "                tn = torch.sum((pred == 0) & (mask == 0)).item()\n",
    "                \n",
    "                # Accumulate totals\n",
    "                total_tp += tp\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tn += tn\n",
    "    \n",
    "    # Calculate metrics from confusion matrix\n",
    "    # Avoid division by zero\n",
    "    smooth = 1e-8\n",
    "    \n",
    "    # Average test loss\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # Sensitivity (Recall) - TP / (TP + FN)\n",
    "    sensitivity = total_tp / (total_tp + total_fn + smooth)\n",
    "    \n",
    "    # Specificity - TN / (TN + FP)\n",
    "    specificity = total_tn / (total_tn + total_fp + smooth)\n",
    "    \n",
    "    # Accuracy - (TP + TN) / (TP + TN + FP + FN)\n",
    "    accuracy = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn + smooth)\n",
    "    \n",
    "    # AUC calculation\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        # Convert predictions to binary for clear threshold\n",
    "        binary_preds_array = np.array([(p > threshold) for p in all_preds])\n",
    "        binary_targets_array = np.array([(t > threshold) for t in all_targets])\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc_score = roc_auc_score(binary_targets_array, binary_preds_array)\n",
    "    except:\n",
    "        print(\"Warning: Could not calculate AUC. Check if sklearn is installed.\")\n",
    "        auc_score = 0.0\n",
    "    \n",
    "    # Store all metrics in a dictionary\n",
    "    metrics = {\n",
    "        'test_loss': avg_test_loss,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nTest Results:\")\n",
    "    print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"Sensitivity (SE): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (SP): {specificity:.4f}\")\n",
    "    print(f\"Accuracy (ACC): {accuracy:.4f}\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_metrics_distribution(metrics_list, metric_name, title=None):\n",
    "    \"\"\"\n",
    "    Plot the distribution of a metric across the test set\n",
    "    \n",
    "    Args:\n",
    "        metrics_list: List of metric values\n",
    "        metric_name: Name of the metric\n",
    "        title: Optional title for the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(metrics_list, bins=20, alpha=0.7, color='blue')\n",
    "    plt.axvline(sum(metrics_list) / len(metrics_list), color='red', linestyle='dashed', linewidth=2)\n",
    "    plt.xlabel(metric_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title or f'Distribution of {metric_name} across Test Set')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_best_worst_examples(model, test_loader, device, metric='dice', n_examples=3):\n",
    "    \"\"\"\n",
    "    Visualize the best and worst examples based on a specified metric\n",
    "    \n",
    "    Args:\n",
    "        model: The trained U-Net model\n",
    "        test_loader: DataLoader for the test set\n",
    "        device: Device to run evaluation on\n",
    "        metric: Metric to use for ranking ('dice', 'iou', etc.)\n",
    "        n_examples: Number of examples to show\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Store predictions, ground truth, metrics, and indices\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    all_preds = []\n",
    "    all_metrics = []\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Get predictions and calculate metrics\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=f\"Finding best/worst examples by {metric}\"):\n",
    "            # Move to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model(images)\n",
    "            binary_preds = (predictions > threshold).float()\n",
    "            \n",
    "            # Store everything\n",
    "            for i in range(len(images)):\n",
    "                # Get single example\n",
    "                img = images[i].cpu()\n",
    "                mask = masks[i].cpu()\n",
    "                pred = binary_preds[i].cpu()\n",
    "                \n",
    "                # Calculate metric\n",
    "                tp = (pred * mask).sum().item()\n",
    "                fp = (pred * (1 - mask)).sum().item()\n",
    "                fn = ((1 - pred) * mask).sum().item()\n",
    "                smooth = 1e-5\n",
    "                \n",
    "                if metric == 'dice' or metric == 'f1':\n",
    "                    val = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
    "                elif metric == 'iou':\n",
    "                    val = (tp + smooth) / (tp + fp + fn + smooth)\n",
    "                elif metric == 'precision':\n",
    "                    val = (tp + smooth) / (tp + fp + smooth)\n",
    "                elif metric == 'recall':\n",
    "                    val = (tp + smooth) / (tp + fn + smooth)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown metric: {metric}\")\n",
    "                \n",
    "                all_images.append(img)\n",
    "                all_masks.append(mask)\n",
    "                all_preds.append(predictions[i].cpu())  # Store raw predictions for visualization\n",
    "                all_metrics.append(val)\n",
    "    \n",
    "    # Get indices of best and worst examples\n",
    "    metrics_array = np.array(all_metrics)\n",
    "    best_indices = metrics_array.argsort()[-n_examples:][::-1]  # Highest values\n",
    "    worst_indices = metrics_array.argsort()[:n_examples]  # Lowest values\n",
    "    \n",
    "    # Function to plot examples\n",
    "    def plot_examples(indices, title):\n",
    "        fig, axes = plt.subplots(len(indices), 3, figsize=(15, 5*len(indices)))\n",
    "        if len(indices) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        plt.suptitle(title, fontsize=16)\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            # Original image\n",
    "            axes[i, 0].imshow(all_images[idx].squeeze(), cmap='gray')\n",
    "            axes[i, 0].set_title('Original Image')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Ground truth\n",
    "            axes[i, 1].imshow(all_masks[idx].squeeze(), cmap='gray')\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Prediction\n",
    "            axes[i, 2].imshow(all_preds[idx].squeeze(), cmap='gray')\n",
    "            axes[i, 2].set_title(f'Prediction ({metric}={all_metrics[idx]:.4f})')\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot best and worst examples\n",
    "    plot_examples(best_indices, f'Best Examples by {metric.upper()}')\n",
    "    plot_examples(worst_indices, f'Worst Examples by {metric.upper()}')\n",
    "\n",
    "def create_confusion_matrix_for_segmentation(model, test_loader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Create an aggregate confusion matrix for the segmentation results\n",
    "    \n",
    "    Args:\n",
    "        model: The trained U-Net model\n",
    "        test_loader: DataLoader for the test set\n",
    "        device: Device to run evaluation on\n",
    "        threshold: Threshold for binary prediction\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize confusion matrix values\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_fn = 0\n",
    "    total_tn = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Calculating Confusion Matrix\"):\n",
    "            # Move to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            predictions = model(images)\n",
    "            binary_preds = (predictions > threshold).float()\n",
    "            \n",
    "            # Update confusion matrix values\n",
    "            for i in range(len(images)):\n",
    "                pred = binary_preds[i].view(-1)\n",
    "                mask = masks[i].view(-1)\n",
    "                \n",
    "                total_tp += (pred * mask).sum().item()\n",
    "                total_fp += (pred * (1 - mask)).sum().item()\n",
    "                total_fn += ((1 - pred) * mask).sum().item()\n",
    "                total_tn += ((1 - pred) * (1 - mask)).sum().item()\n",
    "    \n",
    "    # Create and plot confusion matrix\n",
    "    conf_matrix = np.array([[total_tn, total_fp], [total_fn, total_tp]])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='.0f', cmap='Blues',\n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.title('Confusion Matrix (Pixel-wise)')\n",
    "    plt.ylabel('Actual Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and return metrics from confusion matrix\n",
    "    accuracy = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn)\n",
    "    precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "    recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"Global Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Global Precision: {precision:.4f}\")\n",
    "    print(f\"Global Recall: {recall:.4f}\")\n",
    "    print(f\"Global F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return conf_matrix, accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def test_model_comprehensive(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation of the model using medical imaging metrics\n",
    "    \n",
    "    Args:\n",
    "        model: The trained U-Net model\n",
    "        test_loader: DataLoader for the test set\n",
    "        criterion: Loss function\n",
    "        device: Device to run evaluation on\n",
    "    \"\"\"\n",
    "    # Import necessary libraries\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "    \n",
    "    print(\"Starting comprehensive model evaluation...\")\n",
    "    \n",
    "    # 1. Calculate all metrics\n",
    "    metrics = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # 2. Collect predictions for visualization\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # Collect a sample of predictions to keep computation manageable\n",
    "    sample_size = 100000\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Collecting predictions for visualization\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Sample predictions to avoid memory issues\n",
    "            batch_preds = predictions.cpu().numpy().flatten()\n",
    "            batch_targets = masks.cpu().numpy().flatten()\n",
    "            \n",
    "            # Use random sampling if batch is very large\n",
    "            if len(batch_preds) > 0:\n",
    "                indices = np.random.choice(\n",
    "                    len(batch_preds), \n",
    "                    min(len(batch_preds), sample_size // len(test_loader)), \n",
    "                    replace=False\n",
    "                )\n",
    "                all_preds.extend(batch_preds[indices])\n",
    "                all_targets.extend(batch_targets[indices])\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # 3. Plot ROC curve\n",
    "    print(\"\\nCalculating and plotting ROC curve...\")\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(all_targets, all_preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(\n",
    "            fpr, tpr, \n",
    "            color='darkorange', \n",
    "            lw=2, \n",
    "            label=f'ROC curve (AUC = {roc_auc:.4f})'\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating ROC curve: {e}\")\n",
    "    \n",
    "    # 4. Visualize confusion matrix\n",
    "    print(\"\\nVisualizing confusion matrix...\")\n",
    "    try:\n",
    "        # Generate binary predictions for matrix\n",
    "        binary_preds = (all_preds > 0.5).astype(int)\n",
    "        binary_targets = (all_targets > 0.5).astype(int)\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(binary_targets, binary_preds)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive']\n",
    "        )\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating confusion matrix: {e}\")\n",
    "    \n",
    "    # 5. Calculate metrics at different thresholds\n",
    "    print(\"\\nAnalyzing threshold impact on metrics...\")\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    results = {\n",
    "        'threshold': [],\n",
    "        'sensitivity': [],\n",
    "        'specificity': [],\n",
    "        'accuracy': []\n",
    "    }\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        binary_preds = (all_preds >= thresh).astype(int)\n",
    "        \n",
    "        # True Positives, etc.\n",
    "        tp = np.sum((binary_preds == 1) & (binary_targets == 1))\n",
    "        tn = np.sum((binary_preds == 0) & (binary_targets == 0))\n",
    "        fp = np.sum((binary_preds == 1) & (binary_targets == 0))\n",
    "        fn = np.sum((binary_preds == 0) & (binary_targets == 1))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        \n",
    "        # Store results\n",
    "        results['threshold'].append(thresh)\n",
    "        results['sensitivity'].append(sensitivity)\n",
    "        results['specificity'].append(specificity)\n",
    "        results['accuracy'].append(accuracy)\n",
    "    \n",
    "    # Plot threshold impact\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(results['threshold'], results['sensitivity'], 'r-', label='Sensitivity (SE)')\n",
    "    plt.plot(results['threshold'], results['specificity'], 'g-', label='Specificity (SP)')\n",
    "    plt.plot(results['threshold'], results['accuracy'], 'b-', label='Accuracy (ACC)')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Impact of Threshold on Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Find optimal threshold balancing sensitivity and specificity\n",
    "    # Youden's J statistic = Sensitivity + Specificity - 1\n",
    "    j_scores = [se + sp - 1 for se, sp in zip(results['sensitivity'], results['specificity'])]\n",
    "    optimal_idx = np.argmax(j_scores)\n",
    "    optimal_threshold = results['threshold'][optimal_idx]\n",
    "    \n",
    "    print(f\"\\nOptimal threshold based on Youden's J statistic: {optimal_threshold:.2f}\")\n",
    "    print(f\"At this threshold:\")\n",
    "    print(f\"  Sensitivity: {results['sensitivity'][optimal_idx]:.4f}\")\n",
    "    print(f\"  Specificity: {results['specificity'][optimal_idx]:.4f}\")\n",
    "    print(f\"  Accuracy: {results['accuracy'][optimal_idx]:.4f}\")\n",
    "    \n",
    "    # 7. Visualize best and worst predictions\n",
    "    print(\"\\nVisualizing example predictions...\")\n",
    "    \n",
    "    def visualize_examples(model, test_loader, device, num_examples=3):\n",
    "        \"\"\"Show some example predictions\"\"\"\n",
    "        model.eval()\n",
    "        examples_shown = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in test_loader:\n",
    "                if examples_shown >= num_examples:\n",
    "                    break\n",
    "                \n",
    "                # Get predictions\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                predictions = model(images)\n",
    "                binary_preds = (predictions > optimal_threshold).float()\n",
    "                \n",
    "                # Move to CPU for visualization\n",
    "                for i in range(len(images)):\n",
    "                    if examples_shown >= num_examples:\n",
    "                        break\n",
    "                    \n",
    "                    img = images[i].cpu().squeeze()\n",
    "                    mask = masks[i].cpu().squeeze()\n",
    "                    pred = predictions[i].cpu().squeeze()\n",
    "                    bin_pred = binary_preds[i].cpu().squeeze()\n",
    "                    \n",
    "                    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "                    \n",
    "                    # Original image\n",
    "                    axes[0].imshow(img, cmap='gray')\n",
    "                    axes[0].set_title('Original Image')\n",
    "                    axes[0].axis('off')\n",
    "                    \n",
    "                    # Ground truth mask\n",
    "                    axes[1].imshow(mask, cmap='gray')\n",
    "                    axes[1].set_title('Ground Truth')\n",
    "                    axes[1].axis('off')\n",
    "                    \n",
    "                    # Raw prediction\n",
    "                    axes[2].imshow(pred, cmap='gray')\n",
    "                    axes[2].set_title(f'Raw Prediction')\n",
    "                    axes[2].axis('off')\n",
    "                    \n",
    "                    # Thresholded prediction\n",
    "                    axes[3].imshow(bin_pred, cmap='gray')\n",
    "                    axes[3].set_title(f'Binary Prediction (t={optimal_threshold:.2f})')\n",
    "                    axes[3].axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # Calculate and display metrics for this example\n",
    "                    tp = torch.sum((bin_pred == 1) & (mask == 1)).item()\n",
    "                    fp = torch.sum((bin_pred == 1) & (mask == 0)).item()\n",
    "                    fn = torch.sum((bin_pred == 0) & (mask == 1)).item()\n",
    "                    tn = torch.sum((bin_pred == 0) & (mask == 0)).item()\n",
    "                    \n",
    "                    example_sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                    example_spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                    example_acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "                    \n",
    "                    print(f\"Example {examples_shown + 1} metrics:\")\n",
    "                    print(f\"  Sensitivity: {example_sens:.4f}\")\n",
    "                    print(f\"  Specificity: {example_spec:.4f}\")\n",
    "                    print(f\"  Accuracy: {example_acc:.4f}\")\n",
    "                    print(\"\")\n",
    "                    \n",
    "                    examples_shown += 1\n",
    "    \n",
    "    visualize_examples(model, test_loader, device)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize model (or load your trained model)\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "# Load saved weights\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "test_metrics = test_model_comprehensive(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "#torch.save(model.state_dict(), 'final_model_best.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_visualize(model, test_loader, device, num_examples=5):\n",
    "    \"\"\"\n",
    "    Make predictions on test data and visualize the results\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get the underlying dataset from the test_loader\n",
    "    test_dataset = test_loader.dataset\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    type(test_dataset)\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for i in range(min(num_examples, len(test_dataset))):\n",
    "            # Get a single example directly from the dataset\n",
    "            image, true_mask = test_dataset[i]\n",
    "            \n",
    "            # Add batch dimension\n",
    "            image = image.unsqueeze(0)\n",
    "            true_mask = true_mask.unsqueeze(0)\n",
    "            \n",
    "            # Move to device\n",
    "            image = image.to(device)\n",
    "            true_mask = true_mask.to(device)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = model(image)\n",
    "            \n",
    "            # Move everything back to CPU for visualization\n",
    "            image = image.cpu()\n",
    "            true_mask = true_mask.cpu()\n",
    "            prediction = prediction.cpu()\n",
    "            \n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Original image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image.squeeze(), cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # True mask\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(true_mask.squeeze(), cmap='gray')\n",
    "            plt.title('True Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Predicted mask\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(prediction.squeeze(), cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def load_model_and_predict(model_path, test_loader, device, num_examples=6):\n",
    "    \"\"\"\n",
    "    Load a saved model and make predictions\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "    \n",
    "    # Load saved weights\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Make predictions\n",
    "    predict_and_visualize(model, test_loader, device, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_visualize(model, test_loader, device, num_examples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_and_predict('best_model.pth', test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider, IntSlider\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_interactive_viewer(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Creates an interactive viewer with sliders for opacity and image selection\n",
    "    \"\"\"\n",
    "    # Get the test dataset\n",
    "    test_dataset = test_loader.dataset\n",
    "    \n",
    "    def view_prediction(image_idx, overlay_opacity):\n",
    "        \"\"\"\n",
    "        Display prediction with adjustable opacity \n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get image and true mask\n",
    "            image, true_mask = test_dataset[image_idx]\n",
    "            \n",
    "            # Add batch dimension and predict\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            prediction = model(image_batch).cpu().squeeze()\n",
    "            \n",
    "            # Create figure\n",
    "            plt.figure(figsize=(30, 10))\n",
    "            \n",
    "            # Original with overlay\n",
    "            plt.imshow(image.squeeze(), cmap='gray')\n",
    "            \n",
    "            # Create masked prediction for overlay\n",
    "            prediction_binary = prediction.float()\n",
    "            prediction_rgba = np.zeros((*prediction.shape, 4))\n",
    "            prediction_rgba[..., 0] = 0.5  # Red channel (half intensity for purple)\n",
    "            prediction_rgba[..., 2] = 0.5  # Blue channel (half intensity for purple)\n",
    "            prediction_rgba[..., 3] = prediction_binary * overlay_opacity  # Alpha channel\n",
    "            \n",
    "            plt.imshow(prediction_rgba, alpha=overlay_opacity)\n",
    "            plt.title('Original + Prediction Overlay')\n",
    "            plt.axis('off')\n",
    "            \n",
    "    \n",
    "    # Create interactive widget\n",
    "    interact(\n",
    "        view_prediction,\n",
    "        image_idx=IntSlider(\n",
    "            min=0,\n",
    "            max=len(test_dataset)-1,\n",
    "            step=1,\n",
    "            value=0,\n",
    "            description='Image:'\n",
    "        ),\n",
    "        overlay_opacity=FloatSlider(\n",
    "            min=0,\n",
    "            max=1,\n",
    "            step=0.1,\n",
    "            value=1.0,\n",
    "            description='Opacity:'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Usage:\n",
    "\"\"\"\n",
    "# Basic version with red overlay:\n",
    "create_interactive_viewer(model, test_loader, device)\n",
    "\n",
    "# Version with color selection:\n",
    "create_interactive_viewer_with_colors(model, test_loader, device)\n",
    "\"\"\"\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "# Load saved weights\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "create_interactive_viewer(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
