{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVeinDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, mask_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "            image_dir (str): Path to image folder\n",
    "            mask_dir (str): Path to mask folder\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image ID\n",
    "        image_id = self.data.iloc[idx]['ImageID']\n",
    "        \n",
    "        # Load image and mask\n",
    "        img_path = os.path.join(self.image_dir, f\"{image_id}.png\")\n",
    "        mask_path = os.path.join(self.mask_dir, f\"{image_id}.jpg\")\n",
    "        \n",
    "        # Open and convert to grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        # Convert to tensor and normalize\n",
    "        image = torch.from_numpy(np.array(image)).float() / 255.0\n",
    "        mask = torch.from_numpy(np.array(mask)).float() / 255.0\n",
    "        \n",
    "        # Add channel dimension\n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = SimpleVeinDataset(\n",
    "    csv_file='../Dataset/dataset.csv',\n",
    "    image_dir='../Dataset/Images',\n",
    "    mask_dir='../Dataset/Masks'\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2, \n",
    "    shuffle=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_display_all_bat_images(csv_file, image_dir, mask_dir):\n",
    "    \"\"\"\n",
    "    Group and display all images from all bats\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "        image_dir (str): Path to image folder\n",
    "        mask_dir (str): Path to mask folder\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Group by BatID\n",
    "    grouped = df.groupby('BatID')\n",
    "    \n",
    "    # Create dataset for loading images\n",
    "    dataset = SimpleVeinDataset(csv_file, image_dir, mask_dir)\n",
    "    \n",
    "    # Get all bat IDs\n",
    "    all_bats = list(grouped.groups.keys())\n",
    "    \n",
    "    for bat_id in all_bats:\n",
    "        # Get all image IDs for this bat\n",
    "        bat_images = grouped.get_group(bat_id)\n",
    "        num_images = len(bat_images)\n",
    "        \n",
    "        # Create a figure with enough subplots for all images and masks\n",
    "        fig, axes = plt.subplots(num_images, 2, figsize=(10, 5*num_images))\n",
    "        plt.suptitle(f'Bat ID: {bat_id}', fontsize=16)\n",
    "        \n",
    "        # If there's only one image, wrap axes in list\n",
    "        if num_images == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        # Load and display each image for this bat\n",
    "        for idx, (_, row) in enumerate(bat_images.iterrows()):\n",
    "            # Find index in dataset\n",
    "            dataset_idx = df[df['ImageID'] == row['ImageID']].index[0]\n",
    "            image, mask = dataset[dataset_idx]\n",
    "            \n",
    "            # Display image\n",
    "            axes[idx, 0].imshow(image.squeeze(), cmap='gray')\n",
    "            axes[idx, 0].set_title(f'Image {row[\"ImageID\"]}')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            # Display mask\n",
    "            axes[idx, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "            axes[idx, 1].set_title(f'Mask {row[\"ImageID\"]}')\n",
    "            axes[idx, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "group_and_display_all_bat_images(\n",
    "    csv_file='your_data.csv',\n",
    "    image_dir='path/to/Images',\n",
    "    mask_dir='path/to/Masks'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "def analyze_bat_distribution(csv_file):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of images across bats\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatId and ImageID columns\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    grouped = df.groupby('BatID')\n",
    "    \n",
    "    # Get distribution statistics\n",
    "    image_counts = grouped.size()\n",
    "    \n",
    "    print(\"\\nBat Image Distribution:\")\n",
    "    print(f\"Total number of bats: {len(image_counts)}\")\n",
    "    print(f\"Total number of images: {len(df)}\")\n",
    "    print(f\"Average images per bat: {image_counts.mean():.2f}\")\n",
    "    print(f\"Min images per bat: {image_counts.min()}\")\n",
    "    print(f\"Max images per bat: {image_counts.max()}\")\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(image_counts, bins='auto')\n",
    "    plt.title('Distribution of Images per Bat')\n",
    "    plt.xlabel('Number of Images')\n",
    "    plt.ylabel('Number of Bats')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display counts for each bat\n",
    "    print(\"\\nDetailed image counts per bat:\")\n",
    "    for bat_id, count in image_counts.items():\n",
    "        print(f\"Bat {bat_id}: {count} images\")\n",
    "\n",
    "\"\"\"\n",
    "**Uncomment this to view all the wing images for each bat!**\n",
    "group_and_display_all_bat_images(\n",
    "    csv_file='../Dataset/dataset.csv',\n",
    "    image_dir='../Dataset/Images',\n",
    "    mask_dir='../Dataset/Masks'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "def create_train_val_test_splits(csv_file, image_dir, mask_dir, test_size=0.2, val_size=0.2, batch_size=2, random_state=42):\n",
    "    \"\"\"\n",
    "    Create train, validation and test splits while keeping all images from the same bat together\n",
    "    \n",
    "    Args:\n",
    "        csv_file (str): Path to CSV with BatID and ImageID columns\n",
    "        image_dir (str): Path to image folder\n",
    "        mask_dir (str): Path to mask folder\n",
    "        test_size (float): Proportion of data to use for testing\n",
    "        val_size (float): Proportion of training data to use for validation\n",
    "        batch_size (int): Batch size for dataloaders\n",
    "        random_state (int): Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Get unique bat IDs\n",
    "    unique_bats = df['BatID'].unique()\n",
    "    \n",
    "    # First split off the test set\n",
    "    train_val_bats, test_bats = train_test_split(\n",
    "        unique_bats, \n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Then split the remaining data into train and validation\n",
    "    train_bats, val_bats = train_test_split(\n",
    "        train_val_bats,\n",
    "        test_size=val_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Create full dataset\n",
    "    full_dataset = SimpleVeinDataset(csv_file, image_dir, mask_dir)\n",
    "    \n",
    "    # Get indices for each split\n",
    "    train_indices = df[df['BatID'].isin(train_bats)].index.tolist()\n",
    "    val_indices = df[df['BatID'].isin(val_bats)].index.tolist()\n",
    "    test_indices = df[df['BatID'].isin(test_bats)].index.tolist()\n",
    "    \n",
    "    # Create subset datasets\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    test_dataset = Subset(full_dataset, test_indices)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        #num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        #num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Print split information\n",
    "    print(\"\\nDataset Split Information:\")\n",
    "    print(f\"Total number of bats: {len(unique_bats)}\")\n",
    "    print(f\"Number of training bats: {len(train_bats)}\")\n",
    "    print(f\"Number of validation bats: {len(val_bats)}\")\n",
    "    print(f\"Number of test bats: {len(test_bats)}\")\n",
    "    print(f\"\\nTotal number of images: {len(df)}\")\n",
    "    print(f\"Number of training images: {len(train_indices)}\")\n",
    "    print(f\"Number of validation images: {len(val_indices)}\")\n",
    "    print(f\"Number of test images: {len(test_indices)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def verify_data_splits(train_loader, val_loader, test_loader, num_samples=2):\n",
    "    \"\"\"\n",
    "    Verify the splits by displaying some samples from each split\n",
    "    \"\"\"\n",
    "    def show_batch(loader, title):\n",
    "        # Get a batch\n",
    "        images, masks = next(iter(loader))\n",
    "        \n",
    "        # Display up to num_samples from the batch\n",
    "        n = min(num_samples, len(images))\n",
    "        fig, axes = plt.subplots(n, 2, figsize=(10, 5*n))\n",
    "        if n == 1:  # Handle case where there's only one sample\n",
    "            axes = axes.reshape(1, -1)\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "        \n",
    "        for i in range(n):\n",
    "            # Display image\n",
    "            axes[i, 0].imshow(images[i].squeeze(), cmap='gray')\n",
    "            axes[i, 0].set_title(f'Image {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Display mask\n",
    "            axes[i, 1].imshow(masks[i].squeeze(), cmap='gray')\n",
    "            axes[i, 1].set_title(f'Mask {i+1}')\n",
    "            axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Show samples from all splits\n",
    "    print(\"\\nDisplaying training samples:\")\n",
    "    show_batch(train_loader, \"Training Samples\")\n",
    "    \n",
    "    print(\"\\nDisplaying validation samples:\")\n",
    "    show_batch(val_loader, \"Validation Samples\")\n",
    "    \n",
    "    print(\"\\nDisplaying test samples:\")\n",
    "    show_batch(test_loader, \"Test Samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the splits\n",
    "train_loader, val_loader, test_loader  = create_train_val_test_splits(\n",
    "    csv_file='../Dataset/dataset.csv',\n",
    "    image_dir='../Dataset/Images',\n",
    "    mask_dir='../Dataset//Masks',\n",
    "    test_size=0.2,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Verify the splits\n",
    "verify_data_splits(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Double Convolution block:\n",
    "    (Conv2d -> BatchNorm -> ReLU) * 2\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        \"\"\"\n",
    "        Standard U-Net architecture\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (1 for grayscale, 3 for RGB)\n",
    "            out_channels (int): Number of output channels (1 for binary segmentation)\n",
    "            features (list): Feature dimensions for each level\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Downsampling/Encoder path\n",
    "        in_feat = in_channels\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_feat, feature))\n",
    "            in_feat = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Upsampling/Decoder path\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature * 2, feature, kernel_size=2, stride=2\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Optional sigmoid for binary segmentation\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store skip connections\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder path\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Reverse skip connections list for easier access\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Decoder path\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)  # Upsample\n",
    "            skip = skip_connections[idx//2]\n",
    "\n",
    "            # Handle cases where input dimensions aren't perfectly divisible by 2\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "            # Concatenate with skip connection\n",
    "            concat_skip = torch.cat((skip, x), dim=1)\n",
    "            \n",
    "            # Double convolution\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        # Final 1x1 convolution and sigmoid\n",
    "        return self.sigmoid(self.final_conv(x))\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(\n",
    "    in_channels=1,  # 1 for grayscale\n",
    "    out_channels=1, # 1 for binary segmentation\n",
    "    features=[64, 128, 256, 512]  # Feature dimensions at each level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimizer and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten predictions and targets\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate Dice coefficient\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, bce_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        dice_loss = self.dice(predictions, targets)\n",
    "        bce_loss = self.bce(predictions, targets)\n",
    "        \n",
    "        return self.dice_weight * dice_loss + self.bce_weight * bce_loss\n",
    "\n",
    "def setup_training(model, learning_rate=1e-4, loss_type='combined'):\n",
    "    \"\"\"\n",
    "    Set up loss function and optimizer for training\n",
    "    \n",
    "    Args:\n",
    "        model: The U-Net model\n",
    "        learning_rate: Learning rate for the optimizer\n",
    "        loss_type: One of 'bce', 'dice', or 'combined'\n",
    "        \n",
    "    Returns:\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "    \"\"\"\n",
    "    # Set up loss function\n",
    "    if loss_type == 'bce':\n",
    "        criterion = nn.BCELoss()\n",
    "    elif loss_type == 'dice':\n",
    "        criterion = DiceLoss()\n",
    "    elif loss_type == 'combined':\n",
    "        criterion = CombinedLoss(dice_weight=0.5, bce_weight=0.5)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Optional: Set up learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    return criterion, optimizer, scheduler\n",
    "\n",
    "\n",
    "# Setup with combined loss\n",
    "criterion, optimizer, scheduler = setup_training(\n",
    "    model,\n",
    "    learning_rate=0.001,\n",
    "    loss_type='combined'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                scheduler, \n",
    "                num_epochs, \n",
    "                device,\n",
    "                save_path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Training loop for U-Net model with improved progress tracking\n",
    "    \"\"\"\n",
    "    # Initialize best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Initialize lists to store metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    print(f\"Starting training at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"Training on device: {device}\")\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    # Main epoch loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_dice = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        print(\"Training...\")\n",
    "        for images, masks in train_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, masks)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if batch_count % 1 == 0:  # Print every batch\n",
    "                print(f\"Batch {batch_count}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average training metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        print(\"\\nValidating...\")\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss = criterion(predictions, masks)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Print progress\n",
    "                if batch_count % 1 == 0:  # Print every batch\n",
    "                    print(f\"Batch {batch_count}/{len(val_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average validation metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
    "        print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "            }, save_path)\n",
    "            print(f'Saved new best model with validation loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Plot current progress\n",
    "        if (epoch + 1) % 5 == 0:  # Plot every 5 epochs\n",
    "            plot_training_history(train_losses, val_losses)\n",
    "    \n",
    "    # Final plot\n",
    "    plot_training_history(train_losses, val_losses)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_training_history(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss history\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=20,\n",
    "    device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
